
import numpy as np
from music21 import *
from collections import Counter

def get_sequences(notes_array,timesteps=32,future_steps=8):

    notes_ = [element for note_ in notes_array for element in note_]
    freq = dict(Counter(notes_))
    frequent_notes = [note_ for note_, count in freq.items() if count>=50]
    
    
    new_music=[]

    for notes in notes_array:
        temp=[]
        for note_ in notes:
            if note_ in frequent_notes:
                temp.append(note_)            
        new_music.append(temp)
        
    new_music = np.array(new_music,dtype=object)


    no_of_timesteps = timesteps
    x = []
    y = []
    for note_ in new_music:
        for i in range(0, len(note_) - (no_of_timesteps+future_steps), 1): 
            #preparing input and output sequences
            input_ = note_[i:i + no_of_timesteps]
            output = note_[i+1+no_of_timesteps:i+1+no_of_timesteps+future_steps]
            
            x.append(input_)
            y.append(output)
            
    x=np.array(x)
    y=np.array(y)

    #preparing input sequence
    unique_notes = list(set(x.ravel()))
    note_to_int = dict((note_, number) for number, note_ in enumerate(unique_notes))
    x_seq=[]
    for i in x:
        temp=[]
        for j in i:
            #assigning unique integer to every note
            temp.append(note_to_int[j])
        x_seq.append(temp)
        
    x_seq = np.array(x_seq)

    y_seq=[]
    for i in y:
        temp=[]
        for j in i:
            #assigning unique integer to every note
            temp.append(note_to_int[j])
        y_seq.append(temp)
        
    y_seq = np.array(y_seq)


    return x_seq,y_seq,unique_notes,note_to_int

from music21 import *
import os 
import numpy as np
from midi_helper import *
import Generate_dataset
import pandas as pd
from sklearn.model_selection import train_test_split

train_size = 0.7
validation_size = 0.2 
test_size = 0.1

path='../schubert/'

#read all the filenames
files=[i for i in os.listdir(path) if i.endswith(".mid")]
notes_array = np.array([read_midi(path+i) for i in files],dtype=object)
# notes_array = np.array(read_midi(path+files[1]))

x_seq , y_seq , unique_notes,note_to_int  = Generate_dataset.get_sequences(notes_array,timesteps=32,future_steps=8)

X_train, X_rem, y_train, y_rem = train_test_split(x_seq,y_seq, train_size=train_size)
X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=float(test_size)/float(validation_size+test_size))

train_dataset = [{'x_tr':X_train[i],'future':y_train[i]} for i in range(0,len(X_train))]
validation_dataset = [{'x_val':X_valid[i],'future':y_valid[i]} for i in range(0,len(X_valid))]
test_dataset = [{'x_test':X_test[i],'future':y_test[i]} for i in range(0,len(X_test))]
# print(len(train_dataset),len(validation_dataset),len(test_dataset))

df_tr = pd.DataFrame(train_dataset)
df_val = pd.DataFrame(validation_dataset)
df_test = pd.DataFrame(test_dataset)
df_notes = pd.DataFrame(unique_notes)

df_tr.to_csv('trainset.csv')
df_val.to_csv('validationset.csv')
df_test.to_csv('testset.csv')
df_notes.to_csv('notes.csv')
# print(unique_notes)

import numpy as np
from music21 import *

def read_midi(file):
    
    print("Loading Music File:",file)
    
    notes=[]
    notes_to_parse = None
    
    #parsing a midi file
    midi = converter.parse(file)
  
    #grouping based on different instruments
    s2 = instrument.partitionByInstrument(midi)

    #Looping over all the instruments
    for part in s2.parts:
    
        #select elements of only piano
        if 'Piano' in str(part): 
        
            notes_to_parse = part.recurse() 
      
            #finding whether a particular element is note or a chord
            for element in notes_to_parse:
                
                #note
                if isinstance(element, note.Note):
                    notes.append(str(element.pitch))
                
                #chord
                elif isinstance(element, chord.Chord):
                    notes.append('.'.join(str(n) for n in element.normalOrder))

    return np.array(notes)

def convert_to_midi(prediction_output):
   
    offset = 0
    output_notes = []

    # create note and chord objects based on the values generated by the model
    for pattern in prediction_output:
        
        # pattern is a chord
        if ('.' in pattern) or pattern.isdigit():
            notes_in_chord = pattern.split('.')
            notes = []
            for current_note in notes_in_chord:
                
                cn=int(current_note)
                new_note = note.Note(cn)
                new_note.storedInstrument = instrument.Piano()
                notes.append(new_note)
                
            new_chord = chord.Chord(notes)
            new_chord.offset = offset
            output_notes.append(new_chord)
            
        # pattern is a note
        else:
            
            new_note = note.Note(pattern)
            new_note.offset = offset
            new_note.storedInstrument = instrument.Piano()
            output_notes.append(new_note)

        # increase offset each iteration so that notes do not stack
        offset += 1
    midi_stream = stream.Stream(output_notes)
    midi_stream.write('midi', fp='music.mid')
